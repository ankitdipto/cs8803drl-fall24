{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FHyac8TQfcC"
      },
      "source": [
        "# Homework 2 Part 2 - Model Based Reinforcement Learning\n",
        "\n",
        "***\n",
        "\n",
        "Written by Albert Wilcox\n",
        "\n",
        "In this homework, you'll implement [PETS](https://arxiv.org/abs/1805.12114), a popular model for simple MBRL tasks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFVQXRMAQfcE"
      },
      "source": [
        "First, in the top right corner make sure you're connected to a T4 GPU since those are the only runtimes we tested these instructions on.\n",
        "\n",
        "Next, Upload the folder 'hw2' from the Git repo into your Google Drive.\n",
        "\n",
        "Finally, ensure that the paths in the following cell are correct and run the following cells to set up your Colab environment and install the necessary requirements. Note that for Colab you do this instead of dealing with the conda environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBxEwdHcQfcE"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import sys\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/hw2')\n",
        "sys.path.append('/content/drive/MyDrive/hw2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ew-kAJJ6QfcF",
        "outputId": "b584799e-2325-4c76-dc64-de86ce64d5c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "software-properties-common is already the newest version (0.99.22.9).\n",
            "The following additional packages will be installed:\n",
            "  libegl-dev libgl-dev libgles-dev libgles1 libglu1-mesa libglu1-mesa-dev libglvnd-core-dev\n",
            "  libglvnd-dev libglx-dev libopengl-dev libosmesa6\n",
            "The following NEW packages will be installed:\n",
            "  libegl-dev libgl-dev libgl1-mesa-dev libgl1-mesa-glx libgles-dev libgles1 libglew-dev\n",
            "  libglu1-mesa libglu1-mesa-dev libglvnd-core-dev libglvnd-dev libglx-dev libopengl-dev libosmesa6\n",
            "  libosmesa6-dev\n",
            "0 upgraded, 15 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 4,020 kB of archives.\n",
            "After this operation, 19.4 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglx-dev amd64 1.4.0-1 [14.1 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgl-dev amd64 1.4.0-1 [101 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libegl-dev amd64 1.4.0-1 [18.0 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libgl1-mesa-glx amd64 23.0.4-0ubuntu1~22.04.1 [5,584 B]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgles1 amd64 1.4.0-1 [11.5 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgles-dev amd64 1.4.0-1 [49.4 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd-core-dev amd64 1.4.0-1 [12.7 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libopengl-dev amd64 1.4.0-1 [3,400 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd-dev amd64 1.4.0-1 [3,162 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgl1-mesa-dev amd64 23.2.1-1ubuntu3.1~22.04.2 [6,842 B]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa amd64 9.0.2-1 [145 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa-dev amd64 9.0.2-1 [231 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libglew-dev amd64 2.2.0-4 [287 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libosmesa6 amd64 23.2.1-1ubuntu3.1~22.04.2 [3,121 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libosmesa6-dev amd64 23.2.1-1ubuntu3.1~22.04.2 [8,984 B]\n",
            "Fetched 4,020 kB in 1s (2,751 kB/s)\n",
            "Selecting previously unselected package libglx-dev:amd64.\n",
            "(Reading database ... 123629 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libglx-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglx-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgl-dev:amd64.\n",
            "Preparing to unpack .../01-libgl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libegl-dev:amd64.\n",
            "Preparing to unpack .../02-libegl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libegl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgl1-mesa-glx:amd64.\n",
            "Preparing to unpack .../03-libgl1-mesa-glx_23.0.4-0ubuntu1~22.04.1_amd64.deb ...\n",
            "Unpacking libgl1-mesa-glx:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n",
            "Selecting previously unselected package libgles1:amd64.\n",
            "Preparing to unpack .../04-libgles1_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgles1:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgles-dev:amd64.\n",
            "Preparing to unpack .../05-libgles-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgles-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libglvnd-core-dev:amd64.\n",
            "Preparing to unpack .../06-libglvnd-core-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglvnd-core-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libopengl-dev:amd64.\n",
            "Preparing to unpack .../07-libopengl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libopengl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libglvnd-dev:amd64.\n",
            "Preparing to unpack .../08-libglvnd-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglvnd-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgl1-mesa-dev:amd64.\n",
            "Preparing to unpack .../09-libgl1-mesa-dev_23.2.1-1ubuntu3.1~22.04.2_amd64.deb ...\n",
            "Unpacking libgl1-mesa-dev:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n",
            "Selecting previously unselected package libglu1-mesa:amd64.\n",
            "Preparing to unpack .../10-libglu1-mesa_9.0.2-1_amd64.deb ...\n",
            "Unpacking libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Selecting previously unselected package libglu1-mesa-dev:amd64.\n",
            "Preparing to unpack .../11-libglu1-mesa-dev_9.0.2-1_amd64.deb ...\n",
            "Unpacking libglu1-mesa-dev:amd64 (9.0.2-1) ...\n",
            "Selecting previously unselected package libglew-dev:amd64.\n",
            "Preparing to unpack .../12-libglew-dev_2.2.0-4_amd64.deb ...\n",
            "Unpacking libglew-dev:amd64 (2.2.0-4) ...\n",
            "Selecting previously unselected package libosmesa6:amd64.\n",
            "Preparing to unpack .../13-libosmesa6_23.2.1-1ubuntu3.1~22.04.2_amd64.deb ...\n",
            "Unpacking libosmesa6:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n",
            "Selecting previously unselected package libosmesa6-dev:amd64.\n",
            "Preparing to unpack .../14-libosmesa6-dev_23.2.1-1ubuntu3.1~22.04.2_amd64.deb ...\n",
            "Unpacking libosmesa6-dev:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n",
            "Setting up libglvnd-core-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libgles1:amd64 (1.4.0-1) ...\n",
            "Setting up libgl1-mesa-glx:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n",
            "Setting up libglx-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Setting up libopengl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libgl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libosmesa6:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n",
            "Setting up libegl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libglu1-mesa-dev:amd64 (9.0.2-1) ...\n",
            "Setting up libosmesa6-dev:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n",
            "Setting up libgles-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libglvnd-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libglew-dev:amd64 (2.2.0-4) ...\n",
            "Setting up libgl1-mesa-dev:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  patchelf\n",
            "0 upgraded, 1 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 72.1 kB of archives.\n",
            "After this operation, 186 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 patchelf amd64 0.14.3-1 [72.1 kB]\n",
            "Fetched 72.1 kB in 0s (237 kB/s)\n",
            "Selecting previously unselected package patchelf.\n",
            "(Reading database ... 123769 files and directories currently installed.)\n",
            "Preparing to unpack .../patchelf_0.14.3-1_amd64.deb ...\n",
            "Unpacking patchelf (0.14.3-1) ...\n",
            "Setting up patchelf (0.14.3-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting d4rl (from -r requirements.txt (line 7))\n",
            "  Cloning https://github.com/Farama-Foundation/d4rl (to revision master) to /tmp/pip-install-kjo0khbw/d4rl_894b9aca177b40c8a34e8776f71b1679\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Farama-Foundation/d4rl /tmp/pip-install-kjo0khbw/d4rl_894b9aca177b40c8a34e8776f71b1679\n",
            "  Resolved https://github.com/Farama-Foundation/d4rl to commit cf0efbd75a9e05f34dfee2f566e163abfa512485\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (1.13.1)\n",
            "Collecting loguru (from -r requirements.txt (line 2))\n",
            "  Downloading loguru-0.7.2-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting enlighten (from -r requirements.txt (line 3))\n",
            "  Downloading enlighten-1.12.4-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Collecting free-mujoco-py (from -r requirements.txt (line 4))\n",
            "  Downloading free_mujoco_py-2.1.6-py3-none-any.whl.metadata (586 bytes)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (3.8.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (0.8.0)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->-r requirements.txt (line 1)) (1.26.4)\n",
            "Collecting blessed>=1.17.7 (from enlighten->-r requirements.txt (line 3))\n",
            "  Downloading blessed-1.20.0-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Collecting prefixed>=0.3.2 (from enlighten->-r requirements.txt (line 3))\n",
            "  Downloading prefixed-0.9.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting Cython<0.30.0,>=0.29.24 (from free-mujoco-py->-r requirements.txt (line 4))\n",
            "  Downloading Cython-0.29.37-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: cffi<2.0.0,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from free-mujoco-py->-r requirements.txt (line 4)) (1.17.1)\n",
            "Collecting fasteners==0.15 (from free-mujoco-py->-r requirements.txt (line 4))\n",
            "  Downloading fasteners-0.15-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting glfw<2.0.0,>=1.4.0 (from free-mujoco-py->-r requirements.txt (line 4))\n",
            "  Downloading glfw-1.12.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: imageio<3.0.0,>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from free-mujoco-py->-r requirements.txt (line 4)) (2.36.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fasteners==0.15->free-mujoco-py->-r requirements.txt (line 4)) (1.16.0)\n",
            "Collecting monotonic>=0.1 (from fasteners==0.15->free-mujoco-py->-r requirements.txt (line 4))\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (2.8.2)\n",
            "Collecting mjrl@ git+https://github.com/aravindr93/mjrl@master#egg=mjrl (from d4rl->-r requirements.txt (line 7))\n",
            "  Cloning https://github.com/aravindr93/mjrl (to revision master) to /tmp/pip-install-kjo0khbw/mjrl_e3604e15b83c4b9db62a1858f4614321\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/aravindr93/mjrl /tmp/pip-install-kjo0khbw/mjrl_e3604e15b83c4b9db62a1858f4614321\n",
            "  Resolved https://github.com/aravindr93/mjrl to commit 3871d93763d3b49c4741e6daeaebbc605fe140dc\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gym<0.24.0 (from d4rl->-r requirements.txt (line 7))\n",
            "  Downloading gym-0.23.1.tar.gz (626 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m626.2/626.2 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mujoco_py (from d4rl->-r requirements.txt (line 7))\n",
            "  Downloading mujoco_py-2.1.2.14-py3-none-any.whl.metadata (669 bytes)\n",
            "Collecting pybullet (from d4rl->-r requirements.txt (line 7))\n",
            "  Downloading pybullet-3.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from d4rl->-r requirements.txt (line 7)) (3.12.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from d4rl->-r requirements.txt (line 7)) (2.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from d4rl->-r requirements.txt (line 7)) (8.1.7)\n",
            "Collecting dm_control>=1.0.3 (from d4rl->-r requirements.txt (line 7))\n",
            "  Downloading dm_control-1.0.25-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.17.7->enlighten->-r requirements.txt (line 3)) (0.2.13)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi<2.0.0,>=1.15.0->free-mujoco-py->-r requirements.txt (line 4)) (2.22)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from dm_control>=1.0.3->d4rl->-r requirements.txt (line 7)) (1.4.0)\n",
            "Collecting dm-env (from dm_control>=1.0.3->d4rl->-r requirements.txt (line 7))\n",
            "  Downloading dm_env-1.6-py3-none-any.whl.metadata (966 bytes)\n",
            "Requirement already satisfied: dm-tree!=0.1.2 in /usr/local/lib/python3.10/dist-packages (from dm_control>=1.0.3->d4rl->-r requirements.txt (line 7)) (0.1.8)\n",
            "Collecting labmaze (from dm_control>=1.0.3->d4rl->-r requirements.txt (line 7))\n",
            "  Downloading labmaze-1.0.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (278 bytes)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from dm_control>=1.0.3->d4rl->-r requirements.txt (line 7)) (5.3.0)\n",
            "Collecting mujoco>=3.2.5 (from dm_control>=1.0.3->d4rl->-r requirements.txt (line 7))\n",
            "  Downloading mujoco-3.2.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.19.4 in /usr/local/lib/python3.10/dist-packages (from dm_control>=1.0.3->d4rl->-r requirements.txt (line 7)) (4.25.5)\n",
            "Requirement already satisfied: pyopengl>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from dm_control>=1.0.3->d4rl->-r requirements.txt (line 7)) (3.1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dm_control>=1.0.3->d4rl->-r requirements.txt (line 7)) (2.32.3)\n",
            "Requirement already satisfied: setuptools!=50.0.0 in /usr/local/lib/python3.10/dist-packages (from dm_control>=1.0.3->d4rl->-r requirements.txt (line 7)) (75.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dm_control>=1.0.3->d4rl->-r requirements.txt (line 7)) (4.66.6)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym<0.24.0->d4rl->-r requirements.txt (line 7)) (3.1.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym<0.24.0->d4rl->-r requirements.txt (line 7)) (0.0.8)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.10/dist-packages (from mujoco>=3.2.5->dm_control>=1.0.3->d4rl->-r requirements.txt (line 7)) (1.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->dm_control>=1.0.3->d4rl->-r requirements.txt (line 7)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->dm_control>=1.0.3->d4rl->-r requirements.txt (line 7)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dm_control>=1.0.3->d4rl->-r requirements.txt (line 7)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->dm_control>=1.0.3->d4rl->-r requirements.txt (line 7)) (2024.8.30)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco>=3.2.5->dm_control>=1.0.3->d4rl->-r requirements.txt (line 7)) (2024.10.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco>=3.2.5->dm_control>=1.0.3->d4rl->-r requirements.txt (line 7)) (6.4.5)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco>=3.2.5->dm_control>=1.0.3->d4rl->-r requirements.txt (line 7)) (4.12.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco>=3.2.5->dm_control>=1.0.3->d4rl->-r requirements.txt (line 7)) (3.21.0)\n",
            "Downloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading enlighten-1.12.4-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading free_mujoco_py-2.1.6-py3-none-any.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fasteners-0.15-py2.py3-none-any.whl (23 kB)\n",
            "Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Cython-0.29.37-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dm_control-1.0.25-py3-none-any.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading glfw-1.12.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.7/203.7 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prefixed-0.9.0-py2.py3-none-any.whl (13 kB)\n",
            "Downloading mujoco_py-2.1.2.14-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybullet-3.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (103.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading mujoco-3.2.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dm_env-1.6-py3-none-any.whl (26 kB)\n",
            "Downloading labmaze-1.0.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m112.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: d4rl, gym, mjrl\n",
            "  Building wheel for d4rl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for d4rl: filename=D4RL-1.1-py3-none-any.whl size=26411920 sha256=31d9901d829c4e8545760842996e09b4982655550dbc759ba3cf827338286b99\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-v14kavqz/wheels/7a/6e/e1/e5d8e3f6d89271fbc022dc955bb64360665044214be4e17251\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.23.1-py3-none-any.whl size=701345 sha256=61e0a7336a889943588fa67eb77faf771caf579191cef6acca9832bd78cf054c\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/00/fb/fe5cf2860fb9b7bc860e28f00095a1f42c7b726dd6f42d1acc\n",
            "  Building wheel for mjrl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mjrl: filename=mjrl-1.0.0-py3-none-any.whl size=61936 sha256=00e577fe469a525e9759b078df52d535cb7b3843b30da9dd8959c9bcf2877112\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-v14kavqz/wheels/8f/99/f9/efd223b38d503df5eaada10ffe96a869fb0c0f3c92d9e43ed0\n",
            "Successfully built d4rl gym mjrl\n",
            "Installing collected packages: pybullet, prefixed, monotonic, mjrl, glfw, loguru, labmaze, gym, fasteners, dm-env, Cython, blessed, mujoco_py, free-mujoco-py, enlighten, mujoco, dm_control, d4rl\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "  Attempting uninstall: Cython\n",
            "    Found existing installation: Cython 3.0.11\n",
            "    Uninstalling Cython-3.0.11:\n",
            "      Successfully uninstalled Cython-3.0.11\n",
            "Successfully installed Cython-0.29.37 blessed-1.20.0 d4rl-1.1 dm-env-1.6 dm_control-1.0.25 enlighten-1.12.4 fasteners-0.15 free-mujoco-py-2.1.6 glfw-1.12.0 gym-0.23.1 labmaze-1.0.6 loguru-0.7.2 mjrl-1.0.0 monotonic-1.6 mujoco-3.2.5 mujoco_py-2.1.2.14 prefixed-0.9.0 pybullet-3.2.6\n"
          ]
        }
      ],
      "source": [
        "!apt-get install -y \\\n",
        "    libgl1-mesa-dev \\\n",
        "    libgl1-mesa-glx \\\n",
        "    libglew-dev \\\n",
        "    libosmesa6-dev \\\n",
        "    software-properties-common\n",
        "\n",
        "!apt-get install -y patchelf\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZFn7qiXQfcG"
      },
      "source": [
        "Now run the following cell. Everything should import correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bScD_qApQfcG",
        "outputId": "0d3d454e-753b-4a79-ffe4-04131b8ae1ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pygame/pkgdata.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
            "  from pkg_resources import resource_stream, resource_exists\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.cloud')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/Cython/Distutils/old_build_ext.py:15: DeprecationWarning: dep_util is Deprecated. Use functions from setuptools instead.\n",
            "  from distutils.dep_util import newer, newer_group\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compiling /usr/local/lib/python3.10/dist-packages/mujoco_py/cymj.pyx because it changed.\n",
            "[1/1] Cythonizing /usr/local/lib/python3.10/dist-packages/mujoco_py/cymj.pyx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:running build_ext\n",
            "INFO:root:building 'mujoco_py.cymj' extension\n",
            "INFO:root:creating /usr/local/lib/python3.10/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_310_linuxcpuextensionbuilder/temp.linux-x86_64-cpython-310/usr/local/lib/python3.10/dist-packages/mujoco_py\n",
            "INFO:root:creating /usr/local/lib/python3.10/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_310_linuxcpuextensionbuilder/temp.linux-x86_64-cpython-310/usr/local/lib/python3.10/dist-packages/mujoco_py/gl\n",
            "INFO:root:x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/mujoco_py -I/usr/local/lib/python3.10/dist-packages/mujoco_py/binaries/linux/mujoco210/include -I/usr/local/lib/python3.10/dist-packages/numpy/core/include -I/usr/include/python3.10 -c /usr/local/lib/python3.10/dist-packages/mujoco_py/cymj.c -o /usr/local/lib/python3.10/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_310_linuxcpuextensionbuilder/temp.linux-x86_64-cpython-310/usr/local/lib/python3.10/dist-packages/mujoco_py/cymj.o -fopenmp -w\n",
            "INFO:root:x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/mujoco_py -I/usr/local/lib/python3.10/dist-packages/mujoco_py/binaries/linux/mujoco210/include -I/usr/local/lib/python3.10/dist-packages/numpy/core/include -I/usr/include/python3.10 -c /usr/local/lib/python3.10/dist-packages/mujoco_py/gl/osmesashim.c -o /usr/local/lib/python3.10/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_310_linuxcpuextensionbuilder/temp.linux-x86_64-cpython-310/usr/local/lib/python3.10/dist-packages/mujoco_py/gl/osmesashim.o -fopenmp -w\n",
            "INFO:root:creating /usr/local/lib/python3.10/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_310_linuxcpuextensionbuilder/lib.linux-x86_64-cpython-310/mujoco_py\n",
            "INFO:root:x86_64-linux-gnu-gcc -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 /usr/local/lib/python3.10/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_310_linuxcpuextensionbuilder/temp.linux-x86_64-cpython-310/usr/local/lib/python3.10/dist-packages/mujoco_py/cymj.o /usr/local/lib/python3.10/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_310_linuxcpuextensionbuilder/temp.linux-x86_64-cpython-310/usr/local/lib/python3.10/dist-packages/mujoco_py/gl/osmesashim.o -L/usr/local/lib/python3.10/dist-packages/mujoco_py/binaries/linux/mujoco210/bin -L/usr/lib/x86_64-linux-gnu -Wl,--enable-new-dtags,-rpath,/usr/local/lib/python3.10/dist-packages/mujoco_py/binaries/linux/mujoco210/bin -lmujoco210 -lglewosmesa -lOSMesa -lGL -o /usr/local/lib/python3.10/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_310_linuxcpuextensionbuilder/lib.linux-x86_64-cpython-310/mujoco_py/cymj.cpython-310-x86_64-linux-gnu.so -fopenmp\n",
            "<frozen importlib._bootstrap>:283: DeprecationWarning: the load_module() method is deprecated and slated for removal in Python 3.12; use exec_module() instead\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<contextlib.ExitStack at 0x7eac97df7670>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "import einops\n",
        "\n",
        "import gym\n",
        "import numpy as np\n",
        "from loguru import logger\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "from typing import Tuple, Optional\n",
        "\n",
        "from src.utils import (\n",
        "    get_device,\n",
        "    set_seed,\n",
        "    demo_policy,\n",
        "    save_frames_as_gif\n",
        ")\n",
        "# Do not remove the following import\n",
        "import src.cartpole_env\n",
        "from src.mpc import MPC\n",
        "from src.mbrl_utils import sample_rollout\n",
        "from src.cartpole_env import CartpoleConfigModule\n",
        "from src.mbrl_sampler import MBRLSampler\n",
        "\n",
        "plt.ion()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "p69Dlb7RQfcG",
        "outputId": "bac335d1-74c3-4a51-e343-a1ae57a97c99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "\u001b[32m2024-11-16 04:58:55.342\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils\u001b[0m:\u001b[36mget_device\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mUsing cuda device.\u001b[0m\n",
            "\u001b[32m2024-11-16 04:58:55.351\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils\u001b[0m:\u001b[36mset_seed\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mRandom seed set as 42.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "SEED: int = 42\n",
        "ENVIRONMENT_NAME: str='MBRLCartpole-v0'\n",
        "\n",
        "# torch related defaults\n",
        "DEVICE = get_device()\n",
        "torch.set_default_dtype(torch.float32)\n",
        "\n",
        "# Use random seeds for reproducibility\n",
        "set_seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSumKkqJQfcH"
      },
      "source": [
        "As before, we start by initializing the environment and printing some useful information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OwzJQuU0QfcH",
        "outputId": "cdffe53e-493b-4d8c-bea0-5f7e31ee75ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2024-11-16 04:58:55.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 7>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mAction Dimension: 1\u001b[0m\n",
            "\u001b[32m2024-11-16 04:58:55.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 8>\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1mAction High: [3.]\u001b[0m\n",
            "\u001b[32m2024-11-16 04:58:55.372\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 9>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mAction Low: [-3.]\u001b[0m\n",
            "\u001b[32m2024-11-16 04:58:55.374\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 10>\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mState Dimension: 4\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "env = gym.make(ENVIRONMENT_NAME)\n",
        "\n",
        "# get the state and action dimensions\n",
        "action_dimension = env.action_space.shape[0]\n",
        "state_dimension = env.observation_space.shape[0]\n",
        "\n",
        "logger.info(f'Action Dimension: {action_dimension}')\n",
        "logger.info(f'Action High: {env.action_space.high}')\n",
        "logger.info(f'Action Low: {env.action_space.low}')\n",
        "logger.info(f'State Dimension: {state_dimension}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0rt4T-hQfcH"
      },
      "source": [
        "### Part 1 - PETS\n",
        "\n",
        "In this part you'll implement the PETS (Chua et al.) dynamics model and use it for model-based control (MPC). There are several important components of this pipeline:\n",
        " * The dynamics model, discussed in more detail in Chua et al, learns to predict the next state $s_{t+1}$ conditioned on the current state-action pair $(s_t, a_t)$.\n",
        " * The cost function outputs the cost of a planned state. In the case of this environment, we provide a ground truth cost function (negative velocity), but in more complicated environments where no ground truth cost function is available it is common to learn it.\n",
        " * Cross entropy method (CEM) is a gradient-free evolutionary optimizer. We use it to optimize sequences of actions, and evaluate these sequences of actions by predicting future states after rolling out the planned actions and computing the total cost of the predicted rollout under the cost function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sPeR6cDQfcI"
      },
      "source": [
        "The first step is to set up our probabilistic dynamics model. As described in Chua et al, this should take in a state and action and output `mean` and `log_std` for a Gaussian distribution over possible future states."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Yw9x1J61QfcI",
        "outputId": "e431de80-2ff4-4254-9b0e-8bc81b3de9fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2024-11-16 04:58:55.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils\u001b[0m:\u001b[36mget_device\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mUsing cuda device.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from src.networks import network\n",
        "\n",
        "class DynamicsModel(nn.Module):\n",
        "    def __init__(self,\n",
        "                 state_dimension: int,\n",
        "                 action_dimension: int,\n",
        "                 min_log_std: float = -5,\n",
        "                 max_log_std: float = 1,\n",
        "                 ):\n",
        "        super(DynamicsModel, self).__init__()\n",
        "\n",
        "        # TODO: fill in the parameters to initialize the prediction network\n",
        "        # Initialize prediction network for mean and log_std\n",
        "        self.min_log_std = min_log_std\n",
        "        self.max_log_std = max_log_std\n",
        "\n",
        "        # Create network with shared layers then split into mean and log_std\n",
        "        self.network = network(\n",
        "            in_dimension=state_dimension + action_dimension,\n",
        "            out_dimension=2 * state_dimension,  # Mean and log_std for each state dim\n",
        "            n_hidden=3,\n",
        "        )\n",
        "\n",
        "    def forward(self, state: torch.Tensor, action: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Forward pass of the dynamics network. Should return mean and log_std of the next state distribution\n",
        "\n",
        "        Args:\n",
        "            state (torch.Tensor): The input state.\n",
        "            action (torch.Tensor): The input action.\n",
        "\n",
        "        Returns:\n",
        "            Tuple[torch.Tensor, torch.Tensor]: The tuple (mean, log_std) of the distribution\n",
        "        \"\"\"\n",
        "\n",
        "        # TODO: predict the mean and log_std of the next state distribution as described above\n",
        "        # Concatenate state and action\n",
        "        inputs = torch.cat([state, action], dim=-1)\n",
        "\n",
        "        # Get network output and split into mean and log_std\n",
        "        output = self.network(inputs)\n",
        "        mean, log_std = torch.chunk(output, 2, dim=-1)\n",
        "\n",
        "        # Clamp log_std for numerical stability\n",
        "        log_std = torch.clamp(log_std, self.min_log_std, self.max_log_std)\n",
        "        return mean, log_std\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDCZlaqnQfcI"
      },
      "source": [
        "The next step is to create an ensemble of dynamics models. There are better ways to implement this, but for the purposes of this assignment we'll simply maintain a list of models and loop through them at inference time. If you have access to a GPU and are interested in speeding up your implementation, you might want to check out https://pytorch.org/tutorials/intermediate/ensembling.html.\n",
        "\n",
        "There are several ways to handle data for ensembles, such as partitioning the dataset or training each network on different minibatches from the same dataset. In this assignment, we randomly sample `n_ensemble` subsets of the data with replacement. For each epoch, we train each member of the ensemble on a different subset and then shuffle the subsets. To better understand this, please refer to `src/mbrl_sampler.py`.\n",
        "\n",
        "TODOs for this section:\n",
        " * Fill in the `forward` function of the dynamics model to predict the mean and log_std from each member of the ensemble for a single batch of states and actions. This is for use during training\n",
        " * Fill in the `compute_cost` function which takes in a single state and a batch of action trajectory candidates and computes the expected cost for each one by rolling out the dynamics model. You should do this using the TS-1 algorithm from Chua et al, meaning for each step you randomly sample a dynamics model from the ensemble. Note the parameter `n_particles`. For each action trajectory candidate, you should sample `n_particles` trajectories and compute the mean between their costs.\n",
        " * Note: the `compute_cost` function will involve creating some large tensors. For tensors with many dimensions to keep track of, I would highly recommend using the `einops` library for rearranging / tiling / etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "R8Z-W6zWQfcI"
      },
      "outputs": [],
      "source": [
        "class EnsembleDynamicsModel(nn.Module):\n",
        "    def __init__(self, state_dimension: int, action_dimension: int, n_ensemble: int):\n",
        "        super(EnsembleDynamicsModel, self).__init__()\n",
        "        self.num_nets = n_ensemble\n",
        "\n",
        "        # TODO: initialize an ensemble of dynamics models\n",
        "        # Hint: You should store the models in an nn.ModuleList so that they appear when we do dynamics_model.parameters()\n",
        "        # Create ensemble of dynamics models\n",
        "        self.networks = nn.ModuleList([\n",
        "            DynamicsModel(state_dimension, action_dimension)\n",
        "            for _ in range(n_ensemble)\n",
        "        ])\n",
        "\n",
        "    def forward(self, state: torch.Tensor, action: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Forward pass of the dynamics network. Should return mean and log_std of the next state distribution for each model in the ensemble\n",
        "\n",
        "        Args:\n",
        "            state (torch.Tensor): The input state, shape (B, n_ensemble, S)\n",
        "            action (torch.Tensor): The input action, shape (B, n_ensemble, A)\n",
        "\n",
        "        Returns:\n",
        "            Tuple[torch.Tensor, torch.Tensor]: The tuple (mean, log_std) of the distributions where each have shape (B, n_ensemble, S)\n",
        "        \"\"\"\n",
        "\n",
        "        # TODO: predict the next state as described above\n",
        "        # Get predictions from each model in ensemble\n",
        "        means, log_stds = [], []\n",
        "\n",
        "        for i, network in enumerate(self.networks):\n",
        "            mean, log_std = network(state[:, i], action[:, i])\n",
        "            means.append(mean)\n",
        "            log_stds.append(log_std)\n",
        "\n",
        "        # Stack predictions along ensemble dimension\n",
        "        mean = torch.stack(means, dim=1)\n",
        "        log_std = torch.stack(log_stds, dim=1)\n",
        "\n",
        "        return mean, log_std\n",
        "\n",
        "    def compute_cost(\n",
        "            self,\n",
        "            state: torch.Tensor,\n",
        "            actions: torch.Tensor,\n",
        "            obs_cost_fn,\n",
        "            act_cost_fn,\n",
        "            n_particles: int = 20,\n",
        "        ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Given a state and a\n",
        "\n",
        "        Args:\n",
        "            state (torch.Tensor): The input state, shape (S,)\n",
        "            actions (torch.Tensor): The action sequence candidates, shape (N, H, A)\n",
        "            obs_cost_fn: A function which takes in a batch of states and returns the cost of each one\n",
        "            act_cost_fn: A function which takes in a batch of actions and returns the cost of each one\n",
        "            n_particles (int): how many particles to sample for each action sequence\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Expected cost for each action candidate, shape (N,)\n",
        "        \"\"\"\n",
        "        n_candidates, horizon, _ = actions.shape\n",
        "\n",
        "        # TODO: predict the trajectory using the TS-1 algorithm from Chua et al\n",
        "        # Hint: You may have issues with NaN values. To deal with this, use the reparameterization trick\n",
        "        #       to sample and then replace NaN costs with a high number\n",
        "        state_dim = state.shape[-1]\n",
        "\n",
        "        # Expand state and actions for particles\n",
        "        state = einops.repeat(state, 's -> (n p) s', n=n_candidates, p=n_particles)\n",
        "        actions = einops.repeat(actions, 'n h a -> (n p) h a', p=n_particles)\n",
        "\n",
        "        total_cost = torch.zeros(n_candidates * n_particles, device=state.device)\n",
        "\n",
        "        # Simulate trajectories\n",
        "        for t in range(horizon):\n",
        "            # Add action cost\n",
        "            total_cost += act_cost_fn(actions[:, t])\n",
        "\n",
        "            # Add state cost\n",
        "            total_cost += obs_cost_fn(state)\n",
        "\n",
        "            # Select random model for each particle (TS1)\n",
        "            model_inds = torch.randint(self.num_nets, (n_candidates * n_particles,), device=state.device)\n",
        "\n",
        "            # Prepare inputs for selected models\n",
        "            curr_state = einops.repeat(state, 's -> b s', b=self.num_nets)\n",
        "            curr_action = einops.repeat(actions[:, t], 'b a -> b n a', n=self.num_nets)\n",
        "\n",
        "            # Get predictions\n",
        "            means, log_stds = self.forward(curr_state, curr_action)\n",
        "\n",
        "            # Select predictions for chosen models\n",
        "            batch_inds = torch.arange(means.shape[0], device=means.device)\n",
        "            mean = means[batch_inds, model_inds]\n",
        "            log_std = log_stds[batch_inds, model_inds]\n",
        "\n",
        "            # Sample next states using reparameterization trick\n",
        "            std = torch.exp(log_std)\n",
        "            eps = torch.randn_like(std)\n",
        "            state = mean + std * eps\n",
        "\n",
        "        # Handle NaN values\n",
        "        costs = total_cost.reshape(n_candidates, n_particles)\n",
        "        costs = torch.where(torch.isnan(costs), torch.full_like(costs, 1e6), costs)\n",
        "\n",
        "        # Average across particles\n",
        "        return costs.mean(dim=1)\n",
        "\n",
        "        #return costs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ad7s9Y7QfcJ"
      },
      "source": [
        "Now that we've set up everything, the last step is to train our model. In the following block we provide some hyperparameters, the ground truth cost functions, and the skeleton of the training loop. You'll need to implement the loss function yourself.\n",
        "\n",
        "Unfortunately MPC is quite slow to run, especially on a CPU. Thus, we've provided you an offline dataset so that you don't need to run the MPC policy to collect online data. The dataset should be sufficient to achieve a reward greater than 150 with a correct implementation.\n",
        "\n",
        "Note: Our implementation achieved a validation loss <0.1.\n",
        "\n",
        "The hyperparameters we provide should work well enough, but if you have access to a GPU you can improve performance by increasing `n_particles`, `popsize` and `num_elites`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JdZX-y10QfcJ",
        "outputId": "14269bd4-5b79-4a84-affe-3e9447a67129",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-8529bab429b4>:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  sampler = MBRLSampler(torch.load('data.pkl'), n_ensemble, batch_size, DEVICE)\n",
            "<ipython-input-9-8529bab429b4>:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  rollouts = torch.load('data.pkl')\n",
            "Network training:  19%|█▉        | 29/150 [00:35<02:11,  1.09s/epoch(s), Training loss=0.147, Reward=None]\n",
            "  0%|          | 0/200 [00:00<?, ?it/s]\n",
            "Network training:  19%|█▉        | 29/150 [00:35<02:27,  1.22s/epoch(s), Training loss=0.147, Reward=None]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "EinopsError",
          "evalue": " Error while processing repeat-reduction pattern \"s -> b s\".\n Input tensor shape: torch.Size([1000, 4]). Additional info: {'b': 5}.\n Wrong shape: expected 1 dims. Received 2-dim tensor.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mEinopsError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/einops/einops.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(tensor, pattern, reduction, **axes_lengths)\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m         \u001b[0mrecipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_transformation_recipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m         return _apply_recipe(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/einops/einops.py\u001b[0m in \u001b[0;36m_prepare_transformation_recipe\u001b[0;34m(pattern, operation, axes_names, ndim)\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomposition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mEinopsError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Wrong shape: expected {len(left.composition)} dims. Received {ndim}-dim tensor.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m         \u001b[0mleft_composition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mEinopsError\u001b[0m: Wrong shape: expected 1 dims. Received 2-dim tensor.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mEinopsError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-8529bab429b4>\u001b[0m in \u001b[0;36m<cell line: 50>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;31m# Sample an eval rollout. Note: If you are not using a GPU you should comment this out and only run eval once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mEVAL_FREQ\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         info = sample_rollout(\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mTASK_HORIZON\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/cs8803drl-fall24/hw2/src/mbrl_utils.py\u001b[0m in \u001b[0;36msample_rollout\u001b[0;34m(env, horizon, policy, noise_stddev, dU, record_fname)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mrecorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mtimes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/cs8803drl-fall24/hw2/src/mpc.py\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, obs, t, get_pred_cost)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             soln = self.optimizer.obtain_solution(\n\u001b[0m\u001b[1;32m     95\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev_sol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                 torch.tensor(self.init_var, device=self.device, dtype=torch.float32)).cpu().numpy()\n",
            "\u001b[0;32m/content/cs8803drl-fall24/hw2/src/cem.py\u001b[0m in \u001b[0;36mobtain_solution\u001b[0;34m(self, init_mean, init_var)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconstrained_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mcosts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0msorted_costs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0melites\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_elites\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/cs8803drl-fall24/hw2/src/mpc.py\u001b[0m in \u001b[0;36m_compile_cost\u001b[0;34m(self, ac_seqs)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meinops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrearrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mac_seqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'n (h a) -> n h a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplan_hor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         costs = self.dynamics_model.compute_cost(\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msy_cur_obs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-51307b0928e1>\u001b[0m in \u001b[0;36mcompute_cost\u001b[0;34m(self, state, actions, obs_cost_fn, act_cost_fn, n_particles)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;31m# Prepare inputs for selected models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mcurr_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meinops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m's -> b s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_nets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0mcurr_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meinops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b a -> b n a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_nets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/einops/einops.py\u001b[0m in \u001b[0;36mrepeat\u001b[0;34m(tensor, pattern, **axes_lengths)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m     \"\"\"\n\u001b[0;32m--> 641\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"repeat\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0maxes_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/einops/einops.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(tensor, pattern, reduction, **axes_lengths)\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"\\n Input is list. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Additional info: {}.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mEinopsError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mEinopsError\u001b[0m:  Error while processing repeat-reduction pattern \"s -> b s\".\n Input tensor shape: torch.Size([1000, 4]). Additional info: {'b': 5}.\n Wrong shape: expected 1 dims. Received 2-dim tensor."
          ]
        }
      ],
      "source": [
        "################################## Hyper-parameters #########################################\n",
        "\n",
        "EPOCHS = 150\n",
        "EVAL_FREQ = 30\n",
        "TASK_HORIZON = 200\n",
        "\n",
        "plan_hor = 25\n",
        "n_particles = 10\n",
        "batch_size = 32\n",
        "n_ensemble = 5\n",
        "maxiters = 5\n",
        "popsize = 100\n",
        "num_elites = 10\n",
        "\n",
        "################################### Cost Functions ###########################################\n",
        "\n",
        "sampler = MBRLSampler(torch.load('data.pkl'), n_ensemble, batch_size, DEVICE)\n",
        "\n",
        "# To make things faster for you we're providing an offline dataset that should be sufficient\n",
        "rollouts = torch.load('data.pkl')\n",
        "all_obs = np.concatenate([rollout['obs'] for rollout in rollouts], axis=0)\n",
        "all_act = np.concatenate([rollout['act'] for rollout in rollouts], axis=0)\n",
        "all_next_obs = np.concatenate([rollout['next_obs'] for rollout in rollouts], axis=0)\n",
        "\n",
        "config = CartpoleConfigModule(DEVICE)\n",
        "dynamics_model = EnsembleDynamicsModel(state_dimension, action_dimension, n_ensemble).to(DEVICE)\n",
        "optimizer = Adam(dynamics_model.parameters(), 1e-3, weight_decay=1e-4)\n",
        "policy = MPC(\n",
        "    observation_space=env.observation_space,\n",
        "    action_space=env.action_space,\n",
        "    obs_cost_fn=config.obs_cost_fn,\n",
        "    act_cost_fn=config.ac_cost_fn,\n",
        "    dynamics_model=dynamics_model,\n",
        "    plan_hor=plan_hor,\n",
        "    n_particles=n_particles,\n",
        "    max_iters=maxiters,\n",
        "    popsize=popsize,\n",
        "    num_elites=num_elites,\n",
        "    alpha=0.1,\n",
        "    device=DEVICE\n",
        ")\n",
        "\n",
        "data_len = all_obs.shape[0]\n",
        "\n",
        "epoch_range = trange(EPOCHS, unit=\"epoch(s)\", desc=\"Network training\")\n",
        "num_batch = int(np.ceil(data_len / batch_size))\n",
        "result = None\n",
        "rews = []\n",
        "\n",
        "for epoch in epoch_range:\n",
        "\n",
        "    for obs, act, next_obs in sampler:\n",
        "\n",
        "        # TODO: compute NLL loss and update the dynamics model\n",
        "        #pass\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Get model predictions\n",
        "        mean, log_std = dynamics_model(obs, act)\n",
        "\n",
        "        # Compute negative log likelihood loss\n",
        "        std = torch.exp(log_std)\n",
        "        nll = 0.5 * (((next_obs - mean) / std) ** 2 + 2 * log_std + np.log(2 * np.pi))\n",
        "        loss = nll.mean()\n",
        "\n",
        "        # Update model\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Compute validation MSE loss\n",
        "    # Note: this is a different loss function than the one you should implement to update the model\n",
        "    val_obs, val_act, val_next_obs = sampler.get_val_data()\n",
        "    mean, _ = dynamics_model(val_obs, val_act)\n",
        "    mse_losses = ((mean - val_next_obs) ** 2).mean()\n",
        "\n",
        "    epoch_range.set_postfix({\n",
        "        \"Training loss\": mse_losses.item(),\n",
        "        'Reward': result\n",
        "    })\n",
        "\n",
        "    # Sample an eval rollout. Note: If you are not using a GPU you should comment this out and only run eval once\n",
        "    if (epoch + 1) % EVAL_FREQ == 0:\n",
        "        info = sample_rollout(\n",
        "            env,\n",
        "            TASK_HORIZON,\n",
        "            policy=policy,\n",
        "        )\n",
        "        result = info['reward_sum']\n",
        "        rews.append(result)\n",
        "\n",
        "torch.save(dynamics_model.state_dict(), 'pets_checkpoint.pth')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUuCIYczQfcJ"
      },
      "source": [
        "Now that you've finished training your dynamics model we can visualize our MPC policy and print out the final reward.\n",
        "\n",
        "Note: If you're running this on a CPU it will likely be quite slow. I would suggest visualizing a much shorter episode and making sure that the policy looks right before running the full 200 step eval."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KRaWHFq_QfcK",
        "outputId": "e5874a60-d067-4984-8b34-72a7fa319f68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-11d3dcc07089>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  dynamics_model.load_state_dict(torch.load('pets_checkpoint.pth'))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'pets_checkpoint.pth'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-11d3dcc07089>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdynamics_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pets_checkpoint.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdynamics_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdynamics_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdemo_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menvironment_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mENVIRONMENT_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgif_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_frames_as_gif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pets'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Total Reward:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_reward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1317\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1319\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pets_checkpoint.pth'"
          ]
        }
      ],
      "source": [
        "dynamics_model.load_state_dict(torch.load('pets_checkpoint.pth'))\n",
        "dynamics_model = dynamics_model.to(DEVICE)\n",
        "frames, total_reward = demo_policy(policy, environment_name=ENVIRONMENT_NAME, steps=200)\n",
        "gif_path = save_frames_as_gif(frames, method_name='pets')\n",
        "print('Total Reward:', total_reward)\n",
        "Image(open(gif_path,'rb').read())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNYjyYIYQfcK"
      },
      "source": [
        "Congrats on finishing the MBRL portion of Assignment 2! Hopefully you enjoyed yourself. Make sure that the visualizations are showing, an eval with a reward greater than 150 is showing above, and that the `pets_policy.gif` is present in the outputs folder.\n",
        "\n",
        "When you're done: export this notebook as an **HTML file** for final submission."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}